{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#**Basic RAG Pipeline Implementation**  \n",
    "\n",
    "**Overview**  \n",
    "This is a basic RAG (Retrieval-Augmented Generation) pipeline implementation using:\n",
    "- LangChain\n",
    "- FAISS (Facebook AI Similarity Search)\n",
    "- OpenAI embeddings\n",
    "- GPT-4o-mini API\n",
    "\n",
    "**Implementation Reference**  \n",
    "[https://github.com/NirDiamant/RAG_Techniques/blob/main/all_rag_techniques/simple_rag.ipynb](https://github.com/NirDiamant/RAG_Techniques/blob/main/all_rag_techniques/simple_rag.ipynb)\n",
    "\n",
    "**Preprocessing**  \n",
    "I preprocessed my grandfather's memoir titled \"My Life Story\" into 10 PDFs (chapters). Each PDF was processed using PyPDFLoader and chunked with RecursiveCharacterTextSplitter. A citation to the source chapter was appended to the end of each chunk to aid in retrieval."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "from dotenv import load_dotenv\n",
    "from helper_functions import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load from .env file that contains the OpenAI API key\n",
    "load_dotenv() \n",
    "\n",
    "# Get OpenAI API key from .env file\n",
    "openai_api_key = os.getenv(\"OPENAI_API_KEY\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make a list of the PDF paths\n",
    "paths = [os.path.join(os.getcwd(), \"RAG Eval\", \"pdfs\", file) for file in os.listdir(os.path.join(os.getcwd(), \"RAG Eval\", \"pdfs\"))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def encode_pdfs(paths, chunk_size, chunk_overlap):\n",
    "    \"\"\"\n",
    "    Encodes multiple PDFs into a vector store using OpenAI embeddings.\n",
    "\n",
    "    Args:\n",
    "        paths: A list of paths to the PDF files.\n",
    "        chunk_size: The desired size of each text chunk.\n",
    "        chunk_overlap: The amount of overlap between consecutive chunks.\n",
    "\n",
    "    Returns:\n",
    "        A FAISS vector store containing the encoded content of the PDFs with citations.\n",
    "    \"\"\"\n",
    "\n",
    "    all_cleaned_texts = []\n",
    "\n",
    "    for path in paths:\n",
    "        # Load PDF documents\n",
    "        loader = PyPDFLoader(path)\n",
    "        documents = loader.load()\n",
    "\n",
    "        # Split documents into chunks\n",
    "        text_splitter = RecursiveCharacterTextSplitter(\n",
    "            chunk_size=chunk_size, chunk_overlap=chunk_overlap, length_function=len\n",
    "        )\n",
    "        texts = text_splitter.split_documents(documents)\n",
    "        cleaned_texts = replace_t_with_space(texts)\n",
    "\n",
    "        # Extract file name from path\n",
    "        file_name = os.path.basename(path)\n",
    "\n",
    "        # Append document citation to the end of each chunk\n",
    "        for text in cleaned_texts:\n",
    "            text.page_content = text.page_content + f\" [Source: {file_name}]\"\n",
    "\n",
    "        all_cleaned_texts.extend(cleaned_texts)\n",
    "\n",
    "    # Create embeddings\n",
    "    embeddings = get_langchain_embedding_provider(EmbeddingProvider.OPENAI)\n",
    "\n",
    "    # Create vector store\n",
    "    vectorstore = FAISS.from_documents(all_cleaned_texts, embeddings)\n",
    "\n",
    "    return vectorstore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Encode the PDFs\n",
    "chunks_vector_store = encode_pdfs(paths, chunk_size=1000, chunk_overlap=200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#save the vector store\n",
    "#chunks_vector_store.save_local(\"basic_rag_citation.json\")\n",
    "\n",
    "#load the vector store\n",
    "chunks_vector_store = FAISS.load_local(\"basic_rag_citation.json\", OpenAIEmbeddings(), allow_dangerous_deserialization=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a retriever\n",
    "chunks_query_retriever = chunks_vector_store.as_retriever(search_kwargs={\"k\": 2})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_RAG(test_query):\n",
    "    \"\"\"\n",
    "    Test the Retrieval-Augmented Generation (RAG) process with a given query. It also prints the context chunks retrieved from the vector store.\n",
    "\n",
    "    Args:\n",
    "        test_query (str): The query to be tested against the vector store created from my Grandfather's memoir.\n",
    "\n",
    "    Returns:\n",
    "        str: The answer generated by the language model based on the retrieved context.\n",
    "    \"\"\"\n",
    "    context = retrieve_context_per_question(test_query, chunks_query_retriever)\n",
    "    llm = ChatOpenAI(temperature=0, model_name=\"gpt-4o-mini\", max_tokens=2000)\n",
    "    question_answer_from_context_chain = create_question_answer_from_context_chain(llm)\n",
    "    answer = answer_question_from_context(test_query, context, question_answer_from_context_chain)\n",
    "    print(\"Response:\", answer[\"answer\"], \"\\n\")\n",
    "    show_context(context)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Response: Laura Lynn Shambaugh is the daughter of Rudy and was born on August 3, 1960. She is mentioned in the context as a young girl who needed glasses and had various adventures related to them. \n",
      "\n",
      "Context 1:\n",
      "a young girl a little younger than Amy. The Archambaults next door had children of similar ages, so \n",
      "Amy and Tim had a lot of playmates. Rudy had become pregnant again, only this time her pregnancy \n",
      "was more of a problem. She was in and out of the hospital many times with various problems. At one \n",
      "point near the end of pregnancy when Rudy was in the hospital, the tissues of her mouth and throat \n",
      "started to break down in response to one of the medications she was given. It was a difficult , life-\n",
      "threatening time for Rudy. Laura Lynn Shambaugh was born August 3, 1960 in good health. Elfleda and \n",
      "Mom Eaton both came out to help the burgeoning family. Rudy’s physician decided that it would be \n",
      "dangerous for her to have another pregnancy, so soon after Laura was born, Rudy had a complete \n",
      "hysterectomy. \n",
      " \n",
      "Therein hangs another tale. While Rudy was recovering from and caring for baby Laura, Mom, Elfleda, [Source: Chapter 5.pdf]\n",
      "\n",
      "\n",
      "Context 2:\n",
      "Just about time for Laura to start to school, it was decided she needed glasses. She got a pair with \n",
      "beautiful plastic frames called “Cotton C andy”. The only problem was that Laura took them off \n",
      "frequently and forgot where she laid them. Then the hunt was on to find them. One day we could not \n",
      "find them - ever. Rudy took Laura to get another pair of glasses. Months later when I went to the \n",
      "basement to get frozen food from our deep freezer, I found Laura’s glasses in the freezer, next to a n \n",
      "opened bag of chocolates. Mystery Solved! – Well…almost. Laura’s new glasses went missing during \n",
      "the summer. We looked all over the house, but she had been playing outdoors also. We checked \n",
      "outdoors. We found the glasses in the bird feeder, safe and sound. \n",
      " \n",
      "Our family became involved in First Presbyterian Church. The kids were in Sunday School with the girls \n",
      "in Junior Choir. Rudy and I taught children Sunday School classes. I taught adult Sunday School classes [Source: Chapter 6.pdf]\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "test_RAG(\"Who is Laura?\")\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
